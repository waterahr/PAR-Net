{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from network.hiarGoogLenetSPP import hiarGoogLeNetSPP\n",
    "from network.hiarGoogLenetWAM import hiarGoogLeNetWAM\n",
    "from network.hiarGoogLenet import hiarGoogLeNet\n",
    "from network.hiarGoogLenet_high import hiarGoogLeNet_high\n",
    "from network.hiarGoogLenet_mid import hiarGoogLeNet_mid\n",
    "from network.hiarGoogLenet_low import hiarGoogLeNet_low\n",
    "from network.hiarBayesGoogLenet import hiarBayesGoogLeNet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import multi_gpu_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, TensorBoard, CSVLogger\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K\n",
    "from angular_losses import weighted_categorical_crossentropy, coarse_to_fine_categorical_crossentropy_lowerbody\n",
    "\n",
    "\n",
    "low_level = [27, 32, 50, 56]#, 61, 62, 63, 64\n",
    "mid_level = [0, 6, 7, 8, 9, 11, 12, 13, 17, 20, 21, 22, 23, 24, 25, 26, 28, 29, 30, 33, 35, 36, 37, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 57, 58, 59, 60]\n",
    "high_level = [1, 2, 3, 4, 5, 10, 14, 15, 16, 18, 19, 31, 34, 40]    class_num = args.classes\n",
    "    alpha = np.zeros((class_num,))\n",
    "\n",
    "\n",
    "    # Data augmentation to pre-processing\n",
    "    heavy_augmentation = True\n",
    "    if heavy_augmentation:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,\n",
    "            samplewise_center=False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=45,\n",
    "            width_shift_range=0.25,\n",
    "            height_shift_range=0.25,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False,\n",
    "            zoom_range=0.5,\n",
    "            channel_shift_range=0.5,\n",
    "            fill_mode='nearest')\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,\n",
    "            samplewise_center=False,\n",
    "            featurewise_std_normalization=False,\n",
    "            samplewise_std_normalization=False,\n",
    "            zca_whitening=False,\n",
    "            rotation_range=0,\n",
    "            width_shift_range=0.125,\n",
    "            height_shift_range=0.125,\n",
    "            horizontal_flip=True,\n",
    "            vertical_flip=False,\n",
    "            fill_mode='nearest')\n",
    "    image_width = args.width\n",
    "    image_height = args.height\n",
    "    filename = r\"../results/PETA.csv\"\n",
    "    data = np.array(pd.read_csv(filename))[:, 1:]\n",
    "    length = len(data)\n",
    "    data_x = np.zeros((length, image_width, image_height, 3))\n",
    "    data_y = np.zeros((length, class_num))\n",
    "    for i in range(length):\n",
    "        #img = image.load_img(path + m)\n",
    "        img = image.load_img(data[i, 0], target_size=(image_width, image_height, 3))\n",
    "        data_x[i] = image.img_to_array(img)\n",
    "        data_y[i] = np.array(data[i, 1:1+class_num], dtype=\"float32\")\n",
    "    data_y = data_y[:, list(np.hstack((low_level, mid_level, high_level)))]\n",
    "    X_test = data_x[11400:]\n",
    "    y_test = data_y[11400:]#, len(low_level)+len(mid_level):\n",
    "    if args.model == \"hiarGoogLeNet_high\":\n",
    "        y_test = y_test[:, len(low_level)+len(mid_level):]\n",
    "    elif args.model == \"hiarGoogLeNet_mid\":\n",
    "        y_test = y_test[:, len(low_level):len(low_level)+len(mid_level)]\n",
    "    elif args.model == \"hiarGoogLeNet_low\":\n",
    "        y_test = y_test[:, :len(low_level)]\n",
    "    print(\"The shape of the X_test is: \", X_test.shape)\n",
    "    print(\"The shape of the y_test is: \", y_test.shape)\n",
    "    \n",
    "    \n",
    "    #googleNet默认输入32*32的图片\n",
    "    if args.model == \"hiarGoogLeNetSPP\":\n",
    "        model = hiarGoogLeNetSPP.build(None, None, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarGoogLeNetWAM\":\n",
    "        model = hiarGoogLeNetWAM.build(None, None, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarGoogLeNet\":\n",
    "        model = hiarGoogLeNet.build(image_width, image_height, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarGoogLeNet_high\":\n",
    "        model = hiarGoogLeNet_high.build(image_width, image_height, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarGoogLeNet_mid\":\n",
    "        model = hiarGoogLeNet_mid.build(image_width, image_height, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarGoogLeNet_low\":\n",
    "        model = hiarGoogLeNet_low.build(image_width, image_height, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    elif args.model == \"hiarBayesGoogLeNet\":\n",
    "        save_name = \"binary61v2_multi\"\n",
    "        model = hiarBayesGoogLeNet.build(image_width, image_height, 3, [len(low_level), len(mid_level), len(high_level)])\n",
    "        loss_func = 'binary_crossentropy'#weighted_categorical_crossentropy(alpha)\n",
    "        loss_weights = None\n",
    "        metrics=['accuracy']\n",
    "    gpus_num = len(args.gpus.split(','))\n",
    "    if gpus_num > 1:\n",
    "        multi_gpu_model(model, gpus=gpus_num)\n",
    "    #model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss=loss_func, optimizer='adam', loss_weights=loss_weights, metrics=metrics)\n",
    "    model.summary()\n",
    "    model.load_weights(args.weight, by_name=True)\n",
    "    \n",
    "    predictions = model.predict(X_test)\n",
    "    print(\"The shape of the predictions_test is: \", predictions.shape)\n",
    "    np.save(\"../results/predictions/\" + args.model + '_' + save_name + \"_predictions50_imagenet_test7600.npy\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10.0.0.64 - - [24/Dec/2018 14:20:08] \"GET / HTTP/1.1\" 200 4071\n",
      "10.0.0.64 - - [24/Dec/2018 14:20:08] \"GET /favicon.ico HTTP/1.1\" 200 4071\n"
     ]
    }
   ],
   "source": [
    "def yingyong(environ, start_response):\n",
    "    from io import StringIO\n",
    "    stdout = StringIO()\n",
    "    print(\"Hello world!\", file=stdout)\n",
    "    print(file=stdout)\n",
    "    h = sorted(environ.items())\n",
    "    for k,v in h:\n",
    "        print(k,'=',repr(v), file=stdout)\n",
    "    start_response(\"200 OK\", [('Content-Type','text/plain; charset=utf-8')])\n",
    "    return [stdout.getvalue().encode(\"utf-8\")]\n",
    "\n",
    "from wsgiref.simple_server import make_server\n",
    "\n",
    "ip = ''\n",
    "port = 9000\n",
    "httpd = make_server(ip, port, yingyong)\n",
    "httpd.serve_forever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
